{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nyc-rolling-sales.csv', encoding='utf-8')\n",
    "df_old_size = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                        False\n",
       "BOROUGH                           False\n",
       "NEIGHBORHOOD                      False\n",
       "BUILDING CLASS CATEGORY           False\n",
       "TAX CLASS AT PRESENT              False\n",
       "BLOCK                             False\n",
       "LOT                               False\n",
       "EASE-MENT                         False\n",
       "BUILDING CLASS AT PRESENT         False\n",
       "ADDRESS                           False\n",
       "APARTMENT NUMBER                  False\n",
       "ZIP CODE                          False\n",
       "RESIDENTIAL UNITS                 False\n",
       "COMMERCIAL UNITS                  False\n",
       "TOTAL UNITS                       False\n",
       "LAND SQUARE FEET                  False\n",
       "GROSS SQUARE FEET                 False\n",
       "YEAR BUILT                        False\n",
       "TAX CLASS AT TIME OF SALE         False\n",
       "BUILDING CLASS AT TIME OF SALE    False\n",
       "SALE PRICE                        False\n",
       "SALE DATE                         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84548 entries, 0 to 84547\n",
      "Data columns (total 22 columns):\n",
      " #   Column                          Non-Null Count  Dtype \n",
      "---  ------                          --------------  ----- \n",
      " 0   Unnamed: 0                      84548 non-null  int64 \n",
      " 1   BOROUGH                         84548 non-null  int64 \n",
      " 2   NEIGHBORHOOD                    84548 non-null  object\n",
      " 3   BUILDING CLASS CATEGORY         84548 non-null  object\n",
      " 4   TAX CLASS AT PRESENT            84548 non-null  object\n",
      " 5   BLOCK                           84548 non-null  int64 \n",
      " 6   LOT                             84548 non-null  int64 \n",
      " 7   EASE-MENT                       84548 non-null  object\n",
      " 8   BUILDING CLASS AT PRESENT       84548 non-null  object\n",
      " 9   ADDRESS                         84548 non-null  object\n",
      " 10  APARTMENT NUMBER                84548 non-null  object\n",
      " 11  ZIP CODE                        84548 non-null  int64 \n",
      " 12  RESIDENTIAL UNITS               84548 non-null  int64 \n",
      " 13  COMMERCIAL UNITS                84548 non-null  int64 \n",
      " 14  TOTAL UNITS                     84548 non-null  int64 \n",
      " 15  LAND SQUARE FEET                84548 non-null  object\n",
      " 16  GROSS SQUARE FEET               84548 non-null  object\n",
      " 17  YEAR BUILT                      84548 non-null  int64 \n",
      " 18  TAX CLASS AT TIME OF SALE       84548 non-null  int64 \n",
      " 19  BUILDING CLASS AT TIME OF SALE  84548 non-null  object\n",
      " 20  SALE PRICE                      84548 non-null  object\n",
      " 21  SALE DATE                       84548 non-null  object\n",
      "dtypes: int64(10), object(12)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ALPHABET CITY', 'CHELSEA', 'CHINATOWN', 'CIVIC CENTER', 'CLINTON',\n",
       "       'EAST VILLAGE', 'FASHION', 'FINANCIAL', 'FLATIRON', 'GRAMERCY',\n",
       "       'GREENWICH VILLAGE-CENTRAL', 'GREENWICH VILLAGE-WEST',\n",
       "       'HARLEM-CENTRAL', 'HARLEM-EAST', 'HARLEM-UPPER', 'HARLEM-WEST',\n",
       "       'INWOOD', 'JAVITS CENTER', 'KIPS BAY', 'LITTLE ITALY',\n",
       "       'LOWER EAST SIDE', 'MANHATTAN VALLEY', 'MIDTOWN CBD',\n",
       "       'MIDTOWN EAST', 'MIDTOWN WEST', 'MORNINGSIDE HEIGHTS',\n",
       "       'MURRAY HILL', 'ROOSEVELT ISLAND', 'SOHO', 'SOUTHBRIDGE',\n",
       "       'TRIBECA', 'UPPER EAST SIDE (59-79)', 'UPPER EAST SIDE (79-96)',\n",
       "       'UPPER EAST SIDE (96-110)', 'UPPER WEST SIDE (59-79)',\n",
       "       'UPPER WEST SIDE (79-96)', 'UPPER WEST SIDE (96-116)',\n",
       "       'WASHINGTON HEIGHTS LOWER', 'WASHINGTON HEIGHTS UPPER', 'BATHGATE',\n",
       "       'BAYCHESTER', 'BEDFORD PARK/NORWOOD', 'BELMONT', 'BRONX PARK',\n",
       "       'BRONXDALE', 'CASTLE HILL/UNIONPORT', 'CITY ISLAND',\n",
       "       'CITY ISLAND-PELHAM STRIP', 'CO-OP CITY', 'COUNTRY CLUB',\n",
       "       'CROTONA PARK', 'EAST RIVER', 'EAST TREMONT', 'FIELDSTON',\n",
       "       'FORDHAM', 'HIGHBRIDGE/MORRIS HEIGHTS', 'HUNTS POINT',\n",
       "       'KINGSBRIDGE HTS/UNIV HTS', 'KINGSBRIDGE/JEROME PARK',\n",
       "       'MELROSE/CONCOURSE', 'MORRIS PARK/VAN NEST', 'MORRISANIA/LONGWOOD',\n",
       "       'MOTT HAVEN/PORT MORRIS', 'MOUNT HOPE/MOUNT EDEN', 'PARKCHESTER',\n",
       "       'PELHAM BAY', 'PELHAM GARDENS', 'PELHAM PARKWAY NORTH',\n",
       "       'PELHAM PARKWAY SOUTH', 'RIVERDALE', 'SCHUYLERVILLE/PELHAM BAY',\n",
       "       'SOUNDVIEW', 'THROGS NECK', 'VAN CORTLANDT PARK', 'WAKEFIELD',\n",
       "       'WESTCHESTER', 'WILLIAMSBRIDGE', 'WOODLAWN', 'BATH BEACH',\n",
       "       'BAY RIDGE', 'BEDFORD STUYVESANT', 'BENSONHURST', 'BERGEN BEACH',\n",
       "       'BOERUM HILL', 'BOROUGH PARK', 'BRIGHTON BEACH',\n",
       "       'BROOKLYN HEIGHTS', 'BROWNSVILLE', 'BUSH TERMINAL', 'BUSHWICK',\n",
       "       'CANARSIE', 'CARROLL GARDENS', 'CLINTON HILL', 'COBBLE HILL',\n",
       "       'COBBLE HILL-WEST', 'CONEY ISLAND', 'CROWN HEIGHTS',\n",
       "       'CYPRESS HILLS', 'DOWNTOWN-FULTON FERRY', 'DOWNTOWN-FULTON MALL',\n",
       "       'DOWNTOWN-METROTECH', 'DYKER HEIGHTS', 'EAST NEW YORK',\n",
       "       'FLATBUSH-CENTRAL', 'FLATBUSH-EAST', 'FLATBUSH-LEFFERTS GARDEN',\n",
       "       'FLATBUSH-NORTH', 'FLATLANDS', 'FORT GREENE', 'GERRITSEN BEACH',\n",
       "       'GOWANUS', 'GRAVESEND', 'GREENPOINT', 'JAMAICA BAY', 'KENSINGTON',\n",
       "       'MADISON', 'MANHATTAN BEACH', 'MARINE PARK', 'MIDWOOD',\n",
       "       'MILL BASIN', 'NAVY YARD', 'OCEAN HILL', 'OCEAN PARKWAY-NORTH',\n",
       "       'OCEAN PARKWAY-SOUTH', 'OLD MILL BASIN', 'PARK SLOPE',\n",
       "       'PARK SLOPE SOUTH', 'PROSPECT HEIGHTS', 'RED HOOK', 'SEAGATE',\n",
       "       'SHEEPSHEAD BAY', 'SPRING CREEK', 'SUNSET PARK',\n",
       "       'WILLIAMSBURG-CENTRAL', 'WILLIAMSBURG-EAST', 'WILLIAMSBURG-NORTH',\n",
       "       'WILLIAMSBURG-SOUTH', 'WINDSOR TERRACE', 'WYCKOFF HEIGHTS',\n",
       "       'AIRPORT LA GUARDIA', 'ARVERNE', 'ASTORIA', 'BAYSIDE',\n",
       "       'BEECHHURST', 'BELLE HARBOR', 'BELLEROSE', 'BRIARWOOD',\n",
       "       'BROAD CHANNEL', 'CAMBRIA HEIGHTS', 'COLLEGE POINT', 'CORONA',\n",
       "       'DOUGLASTON', 'EAST ELMHURST', 'ELMHURST', 'FAR ROCKAWAY',\n",
       "       'FLORAL PARK', 'FLUSHING MEADOW PARK', 'FLUSHING-NORTH',\n",
       "       'FLUSHING-SOUTH', 'FOREST HILLS', 'FRESH MEADOWS', 'GLEN OAKS',\n",
       "       'GLENDALE', 'HAMMELS', 'HILLCREST', 'HOLLIS', 'HOLLIS HILLS',\n",
       "       'HOLLISWOOD', 'HOWARD BEACH', 'JACKSON HEIGHTS', 'JAMAICA',\n",
       "       'JAMAICA ESTATES', 'JAMAICA HILLS', 'KEW GARDENS', 'LAURELTON',\n",
       "       'LITTLE NECK', 'LONG ISLAND CITY', 'MASPETH', 'MIDDLE VILLAGE',\n",
       "       'NEPONSIT', 'OAKLAND GARDENS', 'OZONE PARK', 'QUEENS VILLAGE',\n",
       "       'REGO PARK', 'RICHMOND HILL', 'RIDGEWOOD', 'ROCKAWAY PARK',\n",
       "       'ROSEDALE', 'SO. JAMAICA-BAISLEY PARK', 'SOUTH JAMAICA',\n",
       "       'SOUTH OZONE PARK', 'SPRINGFIELD GARDENS', 'ST. ALBANS',\n",
       "       'SUNNYSIDE', 'WHITESTONE', 'WOODHAVEN', 'WOODSIDE', 'ANNADALE',\n",
       "       'ARDEN HEIGHTS', 'ARROCHAR', 'ARROCHAR-SHORE ACRES', 'BLOOMFIELD',\n",
       "       'BULLS HEAD', 'CASTLETON CORNERS', 'CLOVE LAKES', 'CONCORD',\n",
       "       'CONCORD-FOX HILLS', 'DONGAN HILLS', 'DONGAN HILLS-COLONY',\n",
       "       'DONGAN HILLS-OLD TOWN', 'ELTINGVILLE', 'EMERSON HILL',\n",
       "       'FRESH KILLS', 'GRANT CITY', 'GRASMERE', 'GREAT KILLS',\n",
       "       'GREAT KILLS-BAY TERRACE', 'GRYMES HILL', 'HUGUENOT', 'LIVINGSTON',\n",
       "       'MANOR HEIGHTS', 'MARINERS HARBOR', 'MIDLAND BEACH',\n",
       "       'NEW BRIGHTON', 'NEW BRIGHTON-ST. GEORGE', 'NEW DORP',\n",
       "       'NEW DORP-BEACH', 'NEW DORP-HEIGHTS', 'NEW SPRINGVILLE', 'OAKWOOD',\n",
       "       'OAKWOOD-BEACH', 'PLEASANT PLAINS', 'PORT IVORY', 'PORT RICHMOND',\n",
       "       'PRINCES BAY', 'RICHMONDTOWN', 'RICHMONDTOWN-LIGHTHS HILL',\n",
       "       'ROSEBANK', 'ROSSVILLE', 'ROSSVILLE-CHARLESTON',\n",
       "       'ROSSVILLE-PORT MOBIL', 'ROSSVILLE-RICHMOND VALLEY', 'SILVER LAKE',\n",
       "       'SOUTH BEACH', 'STAPLETON', 'STAPLETON-CLIFTON', 'TODT HILL',\n",
       "       'TOMPKINSVILLE', 'TOTTENVILLE', 'TRAVIS', 'WEST NEW BRIGHTON',\n",
       "       'WESTERLEIGH', 'WILLOWBROOK', 'WOODROW'], dtype=object)"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NEIGHBORHOOD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NEIGHBORHOOD'] = pd.factorize(df['NEIGHBORHOOD'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['07 RENTALS - WALKUP APARTMENTS             ',\n",
       "       '08 RENTALS - ELEVATOR APARTMENTS           ',\n",
       "       '09 COOPS - WALKUP APARTMENTS               ',\n",
       "       '10 COOPS - ELEVATOR APARTMENTS             ',\n",
       "       '11A CONDO-RENTALS                           ',\n",
       "       '12 CONDOS - WALKUP APARTMENTS              ',\n",
       "       '13 CONDOS - ELEVATOR APARTMENTS            ',\n",
       "       '14 RENTALS - 4-10 UNIT                     ',\n",
       "       '15 CONDOS - 2-10 UNIT RESIDENTIAL          ',\n",
       "       '16 CONDOS - 2-10 UNIT WITH COMMERCIAL UNIT ',\n",
       "       '17 CONDO COOPS                             ',\n",
       "       '22 STORE BUILDINGS                         ',\n",
       "       '37 RELIGIOUS FACILITIES                    ',\n",
       "       '42 CONDO CULTURAL/MEDICAL/EDUCATIONAL/ETC  ',\n",
       "       '46 CONDO STORE BUILDINGS                   ',\n",
       "       '47 CONDO NON-BUSINESS STORAGE              ',\n",
       "       '01 ONE FAMILY DWELLINGS                    ',\n",
       "       '02 TWO FAMILY DWELLINGS                    ',\n",
       "       '03 THREE FAMILY DWELLINGS                  ',\n",
       "       '04 TAX CLASS 1 CONDOS                      ',\n",
       "       '21 OFFICE BUILDINGS                        ',\n",
       "       '23 LOFT BUILDINGS                          ',\n",
       "       '25 LUXURY HOTELS                           ',\n",
       "       '26 OTHER HOTELS                            ',\n",
       "       '28 COMMERCIAL CONDOS                       ',\n",
       "       '29 COMMERCIAL GARAGES                      ',\n",
       "       '35 INDOOR PUBLIC AND CULTURAL FACILITIES   ',\n",
       "       '38 ASYLUMS AND HOMES                       ',\n",
       "       '43 CONDO OFFICE BUILDINGS                  ',\n",
       "       '44 CONDO PARKING                           ',\n",
       "       '48 CONDO TERRACES/GARDENS/CABANAS          ',\n",
       "       '31 COMMERCIAL VACANT LAND                  ',\n",
       "       '32 HOSPITAL AND HEALTH FACILITIES          ',\n",
       "       '41 TAX CLASS 4 - OTHER                     ',\n",
       "       '18 TAX CLASS 3 - UNTILITY PROPERTIES       ',\n",
       "       '30 WAREHOUSES                              ',\n",
       "       '36 OUTDOOR RECREATIONAL FACILITIES         ',\n",
       "       '49 CONDO WAREHOUSES/FACTORY/INDUS          ',\n",
       "       '34 THEATRES                                ',\n",
       "       '27 FACTORIES                               ',\n",
       "       '40 SELECTED GOVERNMENTAL FACILITIES        ',\n",
       "       '45 CONDO HOTELS                            ',\n",
       "       '33 EDUCATIONAL FACILITIES                  ',\n",
       "       '11 SPECIAL CONDO BILLING LOTS              ',\n",
       "       '05 TAX CLASS 1 VACANT LAND                 ',\n",
       "       '06 TAX CLASS 1 - OTHER                     ',\n",
       "       '39 TRANSPORTATION FACILITIES               '], dtype=object)"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BUILDING CLASS CATEGORY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BUILDING CLASS CATEGORY'] = pd.factorize(df['BUILDING CLASS CATEGORY'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2A', '2', '2B', '2C', ' ', '4', '1', '1C', '3', '1A', '1B'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TAX CLASS AT PRESENT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TAX CLASS AT PRESENT'] = pd.factorize(df['TAX CLASS AT PRESENT'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C2', 'C7', 'C4', 'D5', 'D9', 'D7', 'D1', 'C6', 'D0', 'D4', 'RR',\n",
       "       ' ', 'R2', 'R4', 'S3', 'S4', 'S5', 'R1', 'R8', 'R9', 'K4', 'M9',\n",
       "       'M3', 'RK', 'RS', 'A9', 'A4', 'B3', 'B1', 'S2', 'C0', 'R6', 'C5',\n",
       "       'C3', 'C1', 'D6', 'S9', 'O2', 'O1', 'O3', 'O5', 'O6', 'K1', 'K2',\n",
       "       'L9', 'L8', 'L1', 'H1', 'H8', 'H3', 'R5', 'G6', 'P7', 'M1', 'N2',\n",
       "       'RB', 'RG', 'RT', 'K9', 'V1', 'GW', 'G2', 'I7', 'M4', 'Z9', 'B9',\n",
       "       'D3', 'G9', 'I9', 'U6', 'O4', 'L3', 'H2', 'E1', 'Z3', 'RW', 'C9',\n",
       "       'J5', 'N9', 'S1', 'A5', 'J8', 'B2', 'C8', 'F5', 'Q1', 'G7', 'G5',\n",
       "       'G4', 'P2', 'Q9', 'Y1', 'RA', 'RP', 'O8', 'HR', 'G1', 'E7', 'I5',\n",
       "       'R3', 'I4', 'H9', 'RH', 'D8', 'HB', 'J4', 'W2', 'P9', 'A7', 'D2',\n",
       "       'S0', 'O7', 'O9', 'W3', 'HS', 'H6', 'J9', 'R0', 'HH', 'W8', 'W6',\n",
       "       'A1', 'K5', 'F1', 'V9', 'A2', 'V0', 'G0', 'F4', 'E9', 'I3', 'W4',\n",
       "       'V3', 'I1', 'A6', 'Q8', 'A3', 'Z0', 'W1', 'U1', 'F2', 'F9', 'GU',\n",
       "       'I6', 'G8', 'P5', 'Y3', 'W9', 'M2', 'G3', 'V6', 'K7', 'K3', 'R7',\n",
       "       'P8', 'K6', 'V2', 'E2', 'Z2', 'T2', 'K8', 'P6', 'A0', 'H4', 'J1',\n",
       "       'CM', 'Z7'], dtype=object)"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BUILDING CLASS AT PRESENT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['BUILDING CLASS AT PRESENT'] != ' ']\n",
    "df['BUILDING CLASS AT PRESENT'] = pd.factorize(df['BUILDING CLASS AT PRESENT'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' '], dtype=object)"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EASE-MENT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"EASE-MENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['153 AVENUE B', '234 EAST 4TH   STREET', '197 EAST 3RD   STREET',\n",
       "       ..., '49 PITNEY AVENUE', '2730 ARTHUR KILL ROAD',\n",
       "       '155 CLAY PIT ROAD'], dtype=object)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ADDRESS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(s):\n",
    "    ns = s.split(' ', 1)\n",
    "    l = len(ns)\n",
    "    return ns[l - 1]\n",
    "\n",
    "df['ADDRESS'] = df['ADDRESS'].apply(clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADDRESS'] = pd.factorize(df['ADDRESS'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', 'RES', 'UNIT1', ..., '115', 'MS-B', '363'], dtype=object)"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['APARTMENT NUMBER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64758"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['APARTMENT NUMBER'] == ' '].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['APARTMENT NUMBER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1633', '4616', '2212', ..., '11088', '208033', '10796'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LAND SQUARE FEET'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 83810\n",
      "nulls count: 25866\n",
      "percent of nulls: 30.862665553036628\n"
     ]
    }
   ],
   "source": [
    "col = pd.to_numeric(df['LAND SQUARE FEET'], errors='coerce')\n",
    "allCs = col.size\n",
    "nullCs = col[col.isnull()].size\n",
    "print('count', allCs, sep=': ') \n",
    "print('nulls count', nullCs, sep=': ')\n",
    "print('percent of nulls', nullCs/allCs*100, sep=': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['LAND SQUARE FEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6440', '18690', '7803', ..., '977', '2683', '64117'], dtype=object)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['GROSS SQUARE FEET'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 83810\n",
      "nulls count: 27226\n",
      "percent of nulls: 32.48538360577496\n"
     ]
    }
   ],
   "source": [
    "col = pd.to_numeric(df['GROSS SQUARE FEET'], errors='coerce')\n",
    "allCs = col.size\n",
    "nullCs = col[col.isnull()].size\n",
    "print('count', allCs, sep=': ') \n",
    "print('nulls count', nullCs, sep=': ')\n",
    "print('percent of nulls', nullCs/allCs*100, sep=': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['GROSS SQUARE FEET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C2', 'C7', 'C4', 'D5', 'D9', 'D7', 'D1', 'C6', 'D0', 'D4', 'RR',\n",
       "       'R2', 'R4', 'S3', 'S4', 'S5', 'R1', 'R8', 'R9', 'K4', 'M9', 'M3',\n",
       "       'RK', 'RS', 'A9', 'A4', 'B3', 'B1', 'S2', 'C0', 'R6', 'C5', 'C3',\n",
       "       'C1', 'D6', 'S9', 'O2', 'O1', 'O3', 'O5', 'O6', 'K1', 'K2', 'L9',\n",
       "       'L8', 'L1', 'H1', 'H8', 'H3', 'R5', 'G9', 'G6', 'P7', 'M1', 'N2',\n",
       "       'RB', 'RG', 'RT', 'K9', 'V1', 'GW', 'G2', 'I7', 'M4', 'Z9', 'B9',\n",
       "       'D3', 'I9', 'U6', 'O4', 'L3', 'H2', 'E1', 'Z3', 'Q1', 'RW', 'C9',\n",
       "       'J5', 'N9', 'S1', 'A5', 'J8', 'B2', 'C8', 'F5', 'G7', 'G5', 'G4',\n",
       "       'P2', 'Q9', 'Y1', 'RA', 'RP', 'O8', 'HR', 'G1', 'E7', 'I5', 'R3',\n",
       "       'I4', 'H9', 'RH', 'D8', 'HB', 'J4', 'W2', 'P9', 'A7', 'D2', 'S0',\n",
       "       'O7', 'O9', 'W3', 'HS', 'H6', 'J9', 'R0', 'HH', 'W8', 'W6', 'A1',\n",
       "       'K5', 'F1', 'V9', 'A2', 'V0', 'G0', 'F4', 'E9', 'I3', 'W4', 'V3',\n",
       "       'I1', 'A6', 'Q8', 'A3', 'Z0', 'W1', 'U1', 'F2', 'F9', 'GU', 'I6',\n",
       "       'G8', 'P5', 'Y3', 'W9', 'M2', 'G3', 'V6', 'K7', 'K3', 'H4', 'R7',\n",
       "       'P8', 'K6', 'V2', 'E2', 'Z2', 'T2', 'K8', 'P6', 'A0', 'J1', 'CM',\n",
       "       'Z7'], dtype=object)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BUILDING CLASS AT TIME OF SALE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BUILDING CLASS AT TIME OF SALE'] = pd.factorize(df['BUILDING CLASS AT TIME OF SALE'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6625000', ' -  ', '3936272', ..., '408092', '11693337', '69300'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SALE PRICE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 83810\n",
      "nulls count: 14496\n",
      "percent of nulls: 17.296265362128622\n"
     ]
    }
   ],
   "source": [
    "col = pd.to_numeric(df['SALE PRICE'], errors='coerce')\n",
    "allCs = col.size\n",
    "nullCs = col[col.isnull()].size\n",
    "print('count', allCs, sep=': ') \n",
    "print('nulls count', nullCs, sep=': ')\n",
    "print('percent of nulls', nullCs/allCs*100, sep=': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SALE PRICE'] = col\n",
    "df = df[pd.notnull(df['SALE PRICE'])]\n",
    "df['SALE PRICE'] = df['SALE PRICE'].apply(lambda x: x * 100).astype('int64')\n",
    "df = df[df['SALE PRICE'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2017-07-19 00:00:00', '2016-09-23 00:00:00',\n",
       "       '2016-11-17 00:00:00', '2016-11-07 00:00:00',\n",
       "       '2016-10-17 00:00:00', '2016-09-06 00:00:00',\n",
       "       '2017-03-10 00:00:00', '2017-04-28 00:00:00',\n",
       "       '2017-06-09 00:00:00', '2017-07-14 00:00:00',\n",
       "       '2017-03-16 00:00:00', '2016-09-01 00:00:00',\n",
       "       '2017-08-17 00:00:00', '2017-08-30 00:00:00',\n",
       "       '2017-06-21 00:00:00', '2017-01-30 00:00:00',\n",
       "       '2017-07-07 00:00:00', '2017-08-04 00:00:00',\n",
       "       '2017-01-09 00:00:00', '2017-04-18 00:00:00',\n",
       "       '2017-08-28 00:00:00', '2017-05-10 00:00:00',\n",
       "       '2016-12-02 00:00:00', '2017-01-31 00:00:00',\n",
       "       '2017-06-28 00:00:00', '2017-08-24 00:00:00',\n",
       "       '2017-06-27 00:00:00', '2017-03-17 00:00:00',\n",
       "       '2017-06-14 00:00:00', '2017-01-17 00:00:00',\n",
       "       '2017-01-11 00:00:00', '2017-04-21 00:00:00',\n",
       "       '2017-06-29 00:00:00', '2016-10-05 00:00:00',\n",
       "       '2017-02-02 00:00:00', '2017-04-13 00:00:00',\n",
       "       '2017-06-06 00:00:00', '2017-07-17 00:00:00',\n",
       "       '2016-12-06 00:00:00', '2017-07-13 00:00:00',\n",
       "       '2017-05-17 00:00:00', '2017-05-31 00:00:00',\n",
       "       '2017-07-12 00:00:00', '2017-01-19 00:00:00',\n",
       "       '2016-12-14 00:00:00', '2017-05-03 00:00:00',\n",
       "       '2016-09-29 00:00:00', '2017-08-07 00:00:00',\n",
       "       '2017-01-20 00:00:00', '2017-02-23 00:00:00',\n",
       "       '2016-09-12 00:00:00', '2017-08-09 00:00:00',\n",
       "       '2017-04-07 00:00:00', '2017-05-11 00:00:00',\n",
       "       '2016-10-13 00:00:00', '2016-10-19 00:00:00',\n",
       "       '2016-12-30 00:00:00', '2016-09-21 00:00:00',\n",
       "       '2016-11-03 00:00:00', '2016-09-07 00:00:00',\n",
       "       '2017-03-31 00:00:00', '2017-02-14 00:00:00',\n",
       "       '2017-02-01 00:00:00', '2017-05-08 00:00:00',\n",
       "       '2017-08-14 00:00:00', '2017-06-23 00:00:00',\n",
       "       '2017-03-27 00:00:00', '2017-07-06 00:00:00',\n",
       "       '2017-06-12 00:00:00', '2017-06-22 00:00:00',\n",
       "       '2017-02-17 00:00:00', '2016-12-23 00:00:00',\n",
       "       '2017-07-24 00:00:00', '2016-12-08 00:00:00',\n",
       "       '2017-04-25 00:00:00', '2016-12-13 00:00:00',\n",
       "       '2017-01-12 00:00:00', '2016-12-07 00:00:00',\n",
       "       '2017-03-03 00:00:00', '2017-01-25 00:00:00',\n",
       "       '2016-12-19 00:00:00', '2016-12-16 00:00:00',\n",
       "       '2016-12-09 00:00:00', '2016-12-29 00:00:00',\n",
       "       '2017-01-13 00:00:00', '2017-02-24 00:00:00',\n",
       "       '2016-12-21 00:00:00', '2017-03-30 00:00:00',\n",
       "       '2017-04-14 00:00:00', '2017-05-22 00:00:00',\n",
       "       '2017-05-19 00:00:00', '2017-02-08 00:00:00',\n",
       "       '2016-11-08 00:00:00', '2017-03-02 00:00:00',\n",
       "       '2017-01-05 00:00:00', '2016-10-11 00:00:00',\n",
       "       '2016-11-15 00:00:00', '2017-04-03 00:00:00',\n",
       "       '2016-11-28 00:00:00', '2016-11-14 00:00:00',\n",
       "       '2017-04-20 00:00:00', '2017-05-05 00:00:00',\n",
       "       '2017-07-18 00:00:00', '2017-05-15 00:00:00',\n",
       "       '2017-07-31 00:00:00', '2017-06-07 00:00:00',\n",
       "       '2016-11-02 00:00:00', '2017-04-19 00:00:00',\n",
       "       '2017-07-11 00:00:00', '2016-09-28 00:00:00',\n",
       "       '2017-04-17 00:00:00', '2016-09-08 00:00:00',\n",
       "       '2016-10-26 00:00:00', '2017-02-06 00:00:00',\n",
       "       '2017-03-23 00:00:00', '2017-08-31 00:00:00',\n",
       "       '2016-11-10 00:00:00', '2016-12-05 00:00:00',\n",
       "       '2016-11-29 00:00:00', '2016-10-28 00:00:00',\n",
       "       '2016-11-21 00:00:00', '2017-01-27 00:00:00',\n",
       "       '2016-09-26 00:00:00', '2017-02-21 00:00:00',\n",
       "       '2016-10-06 00:00:00', '2017-08-25 00:00:00',\n",
       "       '2016-11-30 00:00:00', '2017-03-01 00:00:00',\n",
       "       '2016-10-31 00:00:00', '2016-11-16 00:00:00',\n",
       "       '2016-11-18 00:00:00', '2017-06-19 00:00:00',\n",
       "       '2017-04-10 00:00:00', '2016-11-23 00:00:00',\n",
       "       '2016-12-27 00:00:00', '2017-05-12 00:00:00',\n",
       "       '2017-02-15 00:00:00', '2017-07-10 00:00:00',\n",
       "       '2017-03-06 00:00:00', '2017-06-30 00:00:00',\n",
       "       '2017-07-26 00:00:00', '2017-03-22 00:00:00',\n",
       "       '2017-03-08 00:00:00', '2016-09-14 00:00:00',\n",
       "       '2017-04-26 00:00:00', '2016-09-27 00:00:00',\n",
       "       '2017-04-27 00:00:00', '2016-12-01 00:00:00',\n",
       "       '2017-01-23 00:00:00', '2016-11-04 00:00:00',\n",
       "       '2016-10-07 00:00:00', '2017-06-05 00:00:00',\n",
       "       '2017-05-23 00:00:00', '2017-01-26 00:00:00',\n",
       "       '2016-12-28 00:00:00', '2017-05-02 00:00:00',\n",
       "       '2017-03-07 00:00:00', '2017-05-01 00:00:00',\n",
       "       '2016-10-14 00:00:00', '2016-12-15 00:00:00',\n",
       "       '2016-11-01 00:00:00', '2016-09-15 00:00:00',\n",
       "       '2016-10-01 00:00:00', '2016-10-24 00:00:00',\n",
       "       '2016-11-11 00:00:00', '2017-02-09 00:00:00',\n",
       "       '2016-10-20 00:00:00', '2017-07-25 00:00:00',\n",
       "       '2017-03-15 00:00:00', '2016-09-16 00:00:00',\n",
       "       '2017-03-29 00:00:00', '2017-06-26 00:00:00',\n",
       "       '2017-06-20 00:00:00', '2016-10-18 00:00:00',\n",
       "       '2016-12-22 00:00:00', '2017-02-16 00:00:00',\n",
       "       '2017-07-27 00:00:00', '2016-09-09 00:00:00',\n",
       "       '2016-11-09 00:00:00', '2017-05-04 00:00:00',\n",
       "       '2017-06-13 00:00:00', '2017-02-10 00:00:00',\n",
       "       '2017-03-20 00:00:00', '2017-03-28 00:00:00',\n",
       "       '2017-04-24 00:00:00', '2017-02-28 00:00:00',\n",
       "       '2017-04-11 00:00:00', '2017-07-20 00:00:00',\n",
       "       '2016-10-25 00:00:00', '2017-05-25 00:00:00',\n",
       "       '2017-08-21 00:00:00', '2017-08-29 00:00:00',\n",
       "       '2017-01-06 00:00:00', '2017-08-01 00:00:00',\n",
       "       '2017-06-08 00:00:00', '2017-08-23 00:00:00',\n",
       "       '2017-06-02 00:00:00', '2017-05-24 00:00:00',\n",
       "       '2017-06-16 00:00:00', '2016-11-22 00:00:00',\n",
       "       '2016-09-13 00:00:00', '2017-03-13 00:00:00',\n",
       "       '2017-01-03 00:00:00', '2017-01-18 00:00:00',\n",
       "       '2017-05-18 00:00:00', '2017-05-30 00:00:00',\n",
       "       '2017-01-10 00:00:00', '2017-08-11 00:00:00',\n",
       "       '2017-06-15 00:00:00', '2017-08-22 00:00:00',\n",
       "       '2017-02-03 00:00:00', '2017-04-06 00:00:00',\n",
       "       '2017-02-07 00:00:00', '2017-05-26 00:00:00',\n",
       "       '2017-08-10 00:00:00', '2017-01-24 00:00:00',\n",
       "       '2017-08-18 00:00:00', '2017-02-13 00:00:00',\n",
       "       '2016-09-30 00:00:00', '2017-04-12 00:00:00',\n",
       "       '2017-05-09 00:00:00', '2017-02-27 00:00:00',\n",
       "       '2017-06-01 00:00:00', '2016-10-03 00:00:00',\n",
       "       '2017-08-15 00:00:00', '2017-08-03 00:00:00',\n",
       "       '2016-09-22 00:00:00', '2017-07-28 00:00:00',\n",
       "       '2016-09-20 00:00:00', '2017-01-04 00:00:00',\n",
       "       '2017-03-21 00:00:00', '2017-08-08 00:00:00',\n",
       "       '2017-07-05 00:00:00', '2017-08-02 00:00:00',\n",
       "       '2017-04-05 00:00:00', '2016-10-27 00:00:00',\n",
       "       '2017-02-22 00:00:00', '2016-12-20 00:00:00',\n",
       "       '2017-03-09 00:00:00', '2017-07-21 00:00:00',\n",
       "       '2016-12-12 00:00:00', '2017-04-04 00:00:00',\n",
       "       '2017-03-24 00:00:00', '2017-01-07 00:00:00',\n",
       "       '2017-05-16 00:00:00', '2016-09-19 00:00:00',\n",
       "       '2017-08-16 00:00:00', '2016-10-21 00:00:00',\n",
       "       '2017-02-20 00:00:00', '2016-10-04 00:00:00',\n",
       "       '2016-09-02 00:00:00', '2017-01-02 00:00:00',\n",
       "       '2016-10-12 00:00:00', '2017-04-29 00:00:00',\n",
       "       '2017-03-14 00:00:00', '2016-09-17 00:00:00',\n",
       "       '2017-07-03 00:00:00', '2016-11-27 00:00:00',\n",
       "       '2017-06-24 00:00:00', '2017-01-21 00:00:00',\n",
       "       '2016-10-10 00:00:00', '2017-05-20 00:00:00',\n",
       "       '2017-04-30 00:00:00', '2017-05-21 00:00:00',\n",
       "       '2016-10-15 00:00:00', '2016-11-25 00:00:00',\n",
       "       '2016-10-30 00:00:00', '2017-01-01 00:00:00',\n",
       "       '2017-02-26 00:00:00', '2016-12-31 00:00:00',\n",
       "       '2016-11-12 00:00:00', '2017-08-27 00:00:00',\n",
       "       '2016-11-26 00:00:00', '2017-01-14 00:00:00',\n",
       "       '2017-04-15 00:00:00', '2017-05-06 00:00:00',\n",
       "       '2017-08-26 00:00:00', '2017-05-27 00:00:00',\n",
       "       '2016-12-26 00:00:00', '2016-12-10 00:00:00',\n",
       "       '2017-01-29 00:00:00', '2016-11-19 00:00:00',\n",
       "       '2017-04-08 00:00:00', '2016-09-10 00:00:00',\n",
       "       '2017-01-16 00:00:00', '2017-07-29 00:00:00',\n",
       "       '2017-06-17 00:00:00', '2017-05-13 00:00:00',\n",
       "       '2017-05-28 00:00:00', '2017-06-11 00:00:00',\n",
       "       '2017-07-08 00:00:00', '2017-07-01 00:00:00',\n",
       "       '2016-10-02 00:00:00', '2017-02-25 00:00:00',\n",
       "       '2016-11-06 00:00:00', '2017-03-11 00:00:00',\n",
       "       '2017-04-22 00:00:00', '2017-01-15 00:00:00',\n",
       "       '2016-10-23 00:00:00', '2016-10-08 00:00:00',\n",
       "       '2017-06-25 00:00:00', '2017-04-01 00:00:00',\n",
       "       '2017-03-04 00:00:00', '2017-02-18 00:00:00',\n",
       "       '2016-09-18 00:00:00', '2017-06-10 00:00:00',\n",
       "       '2017-07-15 00:00:00', '2016-12-17 00:00:00',\n",
       "       '2017-05-29 00:00:00', '2016-11-24 00:00:00',\n",
       "       '2016-09-24 00:00:00', '2017-03-18 00:00:00',\n",
       "       '2017-04-02 00:00:00', '2017-04-09 00:00:00',\n",
       "       '2017-01-28 00:00:00', '2017-03-26 00:00:00',\n",
       "       '2017-03-05 00:00:00', '2017-04-16 00:00:00',\n",
       "       '2016-10-29 00:00:00', '2017-05-14 00:00:00',\n",
       "       '2017-08-12 00:00:00', '2017-07-23 00:00:00',\n",
       "       '2016-10-22 00:00:00', '2017-06-03 00:00:00',\n",
       "       '2017-05-07 00:00:00', '2016-11-05 00:00:00',\n",
       "       '2017-02-19 00:00:00', '2017-03-19 00:00:00',\n",
       "       '2017-08-19 00:00:00', '2016-10-16 00:00:00',\n",
       "       '2017-06-18 00:00:00', '2016-12-03 00:00:00',\n",
       "       '2017-07-09 00:00:00', '2016-09-03 00:00:00',\n",
       "       '2017-08-05 00:00:00', '2016-12-11 00:00:00',\n",
       "       '2016-11-20 00:00:00', '2017-02-12 00:00:00',\n",
       "       '2016-12-24 00:00:00', '2016-10-09 00:00:00',\n",
       "       '2017-06-04 00:00:00', '2016-09-05 00:00:00'], dtype=object)"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SALE DATE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 59166\n",
      "nulls count: 0\n",
      "percent of nulls: 0.0\n"
     ]
    }
   ],
   "source": [
    "col = pd.to_datetime(df['SALE DATE'], errors='coerce')\n",
    "allCs = col.size\n",
    "nullCs = col[col.isnull()].size\n",
    "print('count', allCs, sep=': ') \n",
    "print('nulls count', nullCs, sep=': ')\n",
    "print('percent of nulls', nullCs/allCs*100, sep=': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(f):\n",
    "    return f // 100000000000\n",
    "\n",
    "#df['SALE DATE'] = col.astype('int64').apply(simplify)\n",
    "#df = df[pd.notnull(df['SALE DATE'])]\n",
    "del df['SALE DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows removed: 25382\n",
      "rows now: 59166\n"
     ]
    }
   ],
   "source": [
    "df_size = df.shape[0]\n",
    "print('rows removed', df_old_size - df_size, sep=': ')\n",
    "print('rows now', df_size, sep=': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59166 entries, 0 to 84547\n",
      "Data columns (total 17 columns):\n",
      " #   Column                          Non-Null Count  Dtype\n",
      "---  ------                          --------------  -----\n",
      " 0   Unnamed: 0                      59166 non-null  int64\n",
      " 1   BOROUGH                         59166 non-null  int64\n",
      " 2   NEIGHBORHOOD                    59166 non-null  int64\n",
      " 3   BUILDING CLASS CATEGORY         59166 non-null  int64\n",
      " 4   TAX CLASS AT PRESENT            59166 non-null  int64\n",
      " 5   BLOCK                           59166 non-null  int64\n",
      " 6   LOT                             59166 non-null  int64\n",
      " 7   BUILDING CLASS AT PRESENT       59166 non-null  int64\n",
      " 8   ADDRESS                         59166 non-null  int64\n",
      " 9   ZIP CODE                        59166 non-null  int64\n",
      " 10  RESIDENTIAL UNITS               59166 non-null  int64\n",
      " 11  COMMERCIAL UNITS                59166 non-null  int64\n",
      " 12  TOTAL UNITS                     59166 non-null  int64\n",
      " 13  YEAR BUILT                      59166 non-null  int64\n",
      " 14  TAX CLASS AT TIME OF SALE       59166 non-null  int64\n",
      " 15  BUILDING CLASS AT TIME OF SALE  59166 non-null  int64\n",
      " 16  SALE PRICE                      59166 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 8.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.loc[:, df.columns != 'SALE PRICE']\n",
    "y = df['SALE PRICE']\n",
    "train_points, test_points, train_values, test_values = train_test_split(x, y, random_state=104, test_size=0.25, shuffle=False, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 4452253696 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[595], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m rf_model \u001b[39m=\u001b[39m ensemble\u001b[39m.\u001b[39mRandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m rf_model\u001b[39m.\u001b[39;49mfit(train_points, train_values)\n\u001b[0;32m      3\u001b[0m test_predict_rf \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mpredict(test_points)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(accuracy_score(test_values, test_predict_rf) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:147\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:242\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:747\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:719\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_utils.pyx:35\u001b[0m, in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 4452253696 bytes"
     ]
    }
   ],
   "source": [
    "rf_model = ensemble.RandomForestClassifier(n_estimators=10)\n",
    "rf_model.fit(train_points, train_values)\n",
    "test_predict_rf = rf_model.predict(test_points)\n",
    "print(accuracy_score(test_values, test_predict_rf) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
